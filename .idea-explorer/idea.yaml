idea:
  title: Do LLMs behave differently when the prompter is human vs another LLM?
  domain: nlp
  hypothesis: 'Large language models (LLMs) may respond differently to prompts depending
    on whether the prompt is written in a human style or an LLM-generated style, even
    when the content is controlled. This suggests that LLMs can recognize the source
    of a prompt and may have different expectations or behaviors based on that recognition.

    '
  background:
    description: It seems clear that LLMs can recognize when a text is from a human
      or an LLM. We could make a reasonable assumption that they "expect" prompts
      to come from humans, have human style. What happens if the prompt, controlled
      for content, reads very LLM? Might they behave differently?
  metadata:
    source: IdeaHub
    source_url: https://hypogenic.ai/ideahub/idea/dyWMLVUlyLEPhuzpQ2Ob
    idea_id: do_llms_behave_differently_whe_20260117_153428_fbac3d69
    created_at: '2026-01-17T15:34:28.556479'
    status: submitted
    github_repo_name: llm-human-vs-llm-ffea-gemini
    github_repo_url: https://github.com/Hypogenic-AI/llm-human-vs-llm-ffea-gemini
